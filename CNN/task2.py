# -*- coding: utf-8 -*-
"""Task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uTgCvW3ZWdZX6iseEVk6rofKdCnf-919
"""

#imports
import torch, torchvision
from torch import nn
from torch import optim
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import torch.nn.functional as F
import cv2
import glob
import numpy as np

#parameters
nb_epoch = 5
nb_batch = 200 #training batch
batch_size = 2000 #testing batch
lr = 0.01
momentum = 0.5
input_size = 28*28
hidden_layers = 100
log_interval = 10 
random_seed = 69 #random seed
torch.backends.cudnn.enabled = False  #disable cuda to make truly repeatable
torch.manual_seed(random_seed)

#classe for network
class myNetwork(nn.Module):
    def __init__(self):
        super(myNetwork, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  #convulational layer 1 with 1 input channel and 10 output channel
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) #convulational layer 2 with 10 input channel and 20 output channel
        self.conv2_drop = nn.Dropout2d(p = 0.5)       #dropout
        self.fc1 = nn.Linear(320, 50)                 #Linearizing with 50 output
        self.fc2 = nn.Linear(50, 10)                  #linearizing with 10 output        

    def forward(self, x):                             #forward function
        x = F.relu(F.max_pool2d(self.conv1(x), 2))    # max pooling 2*2
        x = F.relu(F.max_pool2d(self.conv2(x), 2))    #max pooling 2*2
        x = x.view(-1, 320)                           
        x = F.relu(self.fc1(x))                       #activation relu
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x)                       #softmax return
  
#similar network but with only first two forward function
class mySubNetwork(nn.Module):                        
    def __init__(self):
        super(mySubNetwork, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d(p = 0.5)
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu( F.max_pool2d( self.conv2_drop( self.conv2(x)), 2 ) )
        return x

# loading dataset and train/test loaders
train_data = torchvision.datasets.MNIST('mnist.data', train = True, download = True, transform = torchvision.transforms.ToTensor())
test_data = torchvision.datasets.MNIST('mnist.data', train = False, download = True, transform = torchvision.transforms.ToTensor())
train_loader = torch.utils.data.DataLoader(train_data, batch_size = nb_batch, shuffle = True, num_workers = 2)
test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, num_workers = 2)
#ennumeration and variable declartion for data and labels
examples = enumerate(test_loader)
batch_idx, (example_data, example_targets) = next(examples)

#checking parameters
test_loader.dataset

#importing drives
from google.colab import drive
drive.mount('/gdrive')

#importing pretrained model and creating new object and optimizing
PATH1 = r"/gdrive/My Drive/trainer/model.pth"
PATH2 = r"/gdrive/My Drive/trainer/optimizer.pth"
model = myNetwork()
model.load_state_dict(torch.load(PATH1))
optimizer = optim.SGD(model.parameters(), lr=lr,
                      momentum=momentum)
optimizer.load_state_dict(torch.load(PATH2))

#checking model
print(model)

#Storing filters of first convolutional layer
Layer1weight = model.conv1.weight
Layer1weight.shape

#plotting layer 1 weights
with torch.no_grad():
  n = "\n"
  fig = plt.figure()
  for i in range(10):
    plt.subplot(5,2,i+1)
    plt.tight_layout()
    plt.imshow(Layer1weight[i][0], interpolation = 'none')
    plt.xticks([])
    plt.yticks([])
  print(f"The shape of {i} filter is {Layer1weight[i][0].shape} ")
  print(f"The weight of {i} filter is{n} {Layer1weight[i][0]}{n}")

#printing weights and plotting their shape and effect on image
with torch.no_grad():
  n = "\n"
 
  for i in range(10):
    fig = plt.figure(figsize = (5,4))
    dst = cv2.filter2D(np.float32(example_data[1][0]),-1, np.float32(Layer1weight[i][0]))
    fig.add_subplot(5,2,1)
    plt.tight_layout()
    plt.xticks([])
    plt.yticks([])
    plt.imshow(Layer1weight[i][0], cmap = 'gray', interpolation = 'none')
    fig.add_subplot(5,2,2)
    plt.tight_layout()
    plt.imshow(dst, cmap = 'gray', interpolation = 'none')
    plt.xticks([])
    plt.yticks([])
  print(f"The shape of {i} filter is {Layer1weight[i][0].shape} ")
  print(f"The weight of {i} filter is{n} {Layer1weight[i][0]}{n}")

#truncated model, creating object and optimizing it
subModel = mySubNetwork()

subModel.load_state_dict(torch.load(PATH1))
optimizer = optim.SGD(model.parameters(), lr=lr,
                      momentum=momentum)
optimizer.load_state_dict(torch.load(PATH2))

#converting first image to right shape
output1 = example_data[1][0].unsqueeze(0).unsqueeze(0)
#implementing submodel on example and writing weight
output2 = subModel(output1)
truncatedlayer1 = subModel.conv2.weight

#convolutional layer 2 weights
from numpy.core.fromnumeric import size
with torch.no_grad():
  n = "\n"
  for i in range(20):
    fig1 = plt.figure(figsize=(5,4))
    dst1 = cv2.filter2D(np.float32(example_data[1][0]),-1, np.float32(truncatedlayer1[i][0]))
    dst2 = cv2.filter2D(np.float32(dst1),-1, np.float32(truncatedlayer1[i][0]))
    fig1.add_subplot(5,2,1)
    plt.tight_layout()
    plt.xticks([])
    plt.yticks([])
    plt.imshow(truncatedlayer1[i][0], cmap = 'gray', interpolation = 'none')
    fig1.add_subplot(5,2,2)
    plt.tight_layout()
    plt.imshow(dst1, cmap = 'gray', interpolation = 'none')
    plt.xticks([])
    plt.yticks([])

#truncated model on first image gives 10 4*4 filters and their effect on image
with torch.no_grad():
  n = "\n"
  
  for i in range(10):
    fig4 = plt.figure()
    
    temp = cv2.filter2D(np.float32(example_data[1][0]),-1, np.float32(output2[0][i]))
    fig4.add_subplot(5,4,1)
    plt.tight_layout()
    plt.xticks([])
    plt.yticks([])
    plt.imshow(output2[0][i], cmap = 'gray', interpolation= 'none')
    fig4.add_subplot(5,4,2)
    plt.tight_layout()
    plt.imshow(temp, cmap = 'gray', interpolation = 'none')
    plt.xticks([])
    plt.yticks([])

